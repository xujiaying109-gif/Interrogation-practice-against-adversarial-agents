# CoT 架构说明（agent_interrogation_CoT\CoT）

本目录实现了一个最小可运行的 CoT（Cognitive Chain-of-Thought）三段式流水线：

1. 感知（Perception）：把审讯官输入结构化为意图/证据强度/实体等信号  
2. 策略（Strategy）：基于心理状态与感知结果，选择对抗策略  
3. 生成（Generate Result）：把策略 + 心理状态 + 事件图谱知识，组织成提示词并调用 LLM 生成嫌疑人回复

> 真实 LLM 的实例化入口来自仓库外部：`Interrogation-practice-against-adversarial-agents-main/0.   配置-config（框架）.py` 的 `get_llm()`。

---

## 目录结构与职责

- `preception_module/`
  - `domain.py`：事件图谱与感知结果的数据结构（`EventGraph`, `TruthEvent`, `FakeEvent`, `RetrievedKnowledge`, `PerceptionResult` 等）
  - `engine.py`：`PerceptionEngine`
    - `analyze_perception()`：从自然语言输入输出 `PerceptionResult`（优先走 LLM，失败回退规则逻辑）
    - `retrieve_knowledge()`：在 `EventGraph` 中检索相关真/假事件，输出 `RetrievedKnowledge`
- `Strategy_module/`
  - `domain.py`：策略与心理状态的数据结构（`Strategy`, `StatusLabel`, `PsychologicalState`, `DeceptionStrategy`）
  - `engine.py`：`StrategyEngine`
    - `select_strategy()`：策略选择入口（优先走 LLM，失败回退矩阵/规则逻辑）
- `generate_result/`
  - `engine.py`：`ResponseGenerator`
    - `generate_response()`：构建 system prompt，并调用真实 LLM 生成回复（可通过 `use_mock_llm=True` 切换为 mock）

入口导出：

- `preception_module/__init__.py` 导出 `PerceptionEngine` 与主要 domain 类型  
- `Strategy_module/__init__.py` 导出 `StrategyEngine` 与主要 domain 类型  
- `generate_result/__init__.py` 导出 `ResponseGenerator`

---

## 核心数据结构（Domain）

### 事件图谱（`preception_module.domain`）

- `EventGraph`
  - `truth_events`: `List[TruthEvent]`
  - `fake_events`: `List[FakeEvent]`
  - `context_events`: `List[ContextEvent]`
- `TruthEvent`：真实事件（可标注 `is_crime`）
- `FakeEvent`：虚假事件（带 `deception_type`, `narrative`, `confidence`）
- `RetrievedKnowledge`：检索结果（真/假/上下文三类事件）

### 感知结果（`preception_module.domain`）

- `Intent`：意图枚举（证据、时间、地点、关系、施压、闲聊等）
- `PerceptionResult`
  - `intent`
  - `evidence_strength`：0~1
  - `is_trap`
  - `normalized_entities`
  - `keywords`
  - `confidence`
  - `query_type`

### 心理与策略（`Strategy_module.domain`）

- `StatusLabel`：心理状态（CALM/DEFENSIVE/ANXIOUS/HESITANT/BROKEN）
- `PsychologicalState`
  - `defense_value`
  - `stress_value`
  - `status_label`
- `Strategy`：对抗策略枚举（direct_denial、deflect、counter_attack 等）
- `DeceptionStrategy`
  - `primary_strategy` / `secondary_strategy`
  - `focus_areas` / `avoid_topics` / `verbal_cues`
  - `risk_level` / `confidence`

---

## 整体流程（框架图）

```mermaid
flowchart LR
  U[审讯官输入 question/user_input] --> P

  subgraph P[PerceptionEngine (preception_module)]
    P1[analyze_perception()\nLLM优先/规则回退] --> PR[PerceptionResult]
    P2[retrieve_knowledge()\nEventGraph检索] --> RK[RetrievedKnowledge]
  end

  subgraph S[StrategyEngine (Strategy_module)]
    S1[select_strategy()\nLLM优先/矩阵回退] --> DS[DeceptionStrategy]
  end

  subgraph G[ResponseGenerator (generate_result)]
    G1[_build_system_prompt()\n策略+心理+知识+历史] --> SP[system_prompt]
    G2[_call_real_llm()\nget_llm().invoke()] --> R[嫌疑人回复 response]
  end

  EG[EventGraph\n(真/假/上下文事件)] --> P2
  PR --> S1
  RK --> S1
  DS --> G1
  PS[PsychologicalState] --> G1
  RK --> G1
  U --> G2
  SP --> G2

  C[外部 LLM 配置\nInterrogation-practice-against-adversarial-agents-main\n0.   配置-config（框架）.py] --> P1
  C --> S1
  C --> G2
```

---

## 运行时调用链（按一轮交互）

1. 输入：审讯官问题 `user_input` + `EventGraph`（案件真/假事件）+ 当前心理状态 `PsychologicalState`
2. 感知：
   - `PerceptionEngine.analyze_perception(user_input, event_graph)` → `PerceptionResult`
   - `PerceptionEngine.retrieve_knowledge(user_input, event_graph, psych_state_dict)` → `RetrievedKnowledge`
3. 策略：
   - `StrategyEngine.select_strategy(state_label, perception, retrieved_knowledge)` → `DeceptionStrategy`
4. 生成：
   - `ResponseGenerator.generate_response(strategy, psych_state, event_graph, retrieved_knowledge, user_input, suspect_profile, conversation_history)` → 嫌疑人回复文本

---

## 真实 LLM 接入方式（当前实现）

三个引擎内部都采用“动态导入配置文件 + `get_llm()`”的方式拿到 LLM 实例，然后用 `invoke()` 调用：

- `preception_module/engine.py`：感知分析 Prompt → 期望返回 JSON（解析失败会回退规则）
- `Strategy_module/engine.py`：策略选择 Prompt → 期望返回 JSON（解析失败会回退矩阵/规则）
- `generate_result/engine.py`：SystemPrompt + UserInput → 直接生成自然语言回复

依赖点：

- 需要 `langchain_core` / `langchain_openai`（由外部配置模块决定）
- 外部配置文件读取环境变量：`OPENAI_API_BASE`, `OPENAI_API_KEY`, `OPENAI_MODEL_NAME`

---

## 扩展与替换建议（保持接口不变）

- 更换知识检索：只要继续返回 `RetrievedKnowledge`（真/假/上下文三类列表），策略与生成侧无需修改
- 更换策略选择：只要返回 `DeceptionStrategy`，生成侧无需修改
- 更换生成器：只要保持 `generate_response(...) -> str`，上层调用无需修改

