import json
from langchain_core.prompts import ChatPromptTemplate
from config import get_llm
from schemas import AgentState, PerceptionOutput
from character import CHARACTER_PROFILE
from knowledge import GLOBAL_KG
from utils import parse_json_from_llm

# 导入动态心理状态机类
from psych_state_machine import DynamicPsychologicalStateMachine


# ==========================================
# 2. 核心逻辑节点 (Nodes)
# ==========================================

# --- 节点 A: 感知 (Perception) ---
def perception_node(state: AgentState):
    """
    对应论文: 4.3 Step 1 Perception (Intent Analysis)
    使用 LLM 分析用户输入的意图、证据强度和是否包含陷阱。
    """
    last_message = state["messages"][-1].content
    print(f"\n--- [1. 感知阶段] 正在分析输入: '{last_message}' ---")

    llm = get_llm(temperature=0.0)

    # [Context Retrieval]
    context_info = GLOBAL_KG.retrieve_all_context(last_message)
    print(f"   -> [Perception Context]: {context_info[:100]}...")

    system_prompt = """你是一个嫌疑人AI的'内部感知模块'。你的任务是分析审讯官的每一句话。

    **Knowledge Context:**
    {context}

    **分析原则 (CRITICAL):**
    1. **Strict Context Checking**: Only claim input matches 'Ground Truth' or 'Fake Story' if the {context} explicitly contains that information.
    2. If {context} is empty or says "无相关背景信息", do NOT hallucinate that the input matches anything. Treat it as "UNKNOWN" or "NEW CLAIM".

    1. **High Threat**: Input matches info in 【客观事实 (Ground Truth)】 but contradicts or is missing from 【当前供词 (Fake Story)】.
    2. **Consistency Check**: Input matches info in 【当前供词 (Fake Story)】.
    3. **Low Threat**: Input matches info in 【背景记忆 (Context)】.
    4. **Trap Detection**: If input claims to have "evidence" (e.g., video, logs) that is NOT in your Ground Truth, it might be a bluff/trap. But if it MATCHES Ground Truth, it is a deadly trap.

    请输出 JSON 对象，字段如下：
    {{
        "intent": "EVIDENCE_PRESENTATION",
        "evidence_strength": 0.0-1.0,
        "is_trap": true/false,
        "analysis": "..."
    }}
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])

    try:
        chain = prompt | llm
        response = chain.invoke({
            "input": last_message,
            "context": context_info
        })
        content = response.content.strip()

        parsed_data = parse_json_from_llm(content)
        perception_result = PerceptionOutput(**parsed_data)

        print(f"   -> [LLM Analysis]: {perception_result.analysis}")
        print(
            f"   -> [Data]: Intent={perception_result.intent}, Trap={perception_result.is_trap}, Strength={perception_result.evidence_strength}")

    except Exception as e:
        print(f"   -> [System Warning] JSON Parsing Failed: {str(e)[:100]}...")
        perception_result = PerceptionOutput(
            intent="PRESSURE",
            evidence_strength=0.5,
            is_trap=False,
            analysis=f"[System Fallback] Model output format error. Treated as generic pressure."
        )

    return {"perception": perception_result.model_dump()}


# --- 节点 B: 心理状态机 (使用独立的 DynamicPsychologicalStateMachine) ---
def psych_update_node(state: AgentState):
    """
    对应论文: 4.2 Dynamic Psychological State Machine (DPSM)
    使用独立的心理状态机类进行状态更新
    """
    print("--- [2. 心理演变] 使用心理状态机更新状态 ---")

    # 从状态中获取或创建心理状态机
    if "psych_machine" not in state:
        # 首次运行，创建心理状态机
        profile_type = state.get("profile_type", "Arrogant")
        psych_machine = DynamicPsychologicalStateMachine(profile_type)
    else:
        psych_machine = state["psych_machine"]

    perception = state["perception"]

    # 根据感知结果确定压力级别
    pressure_level = 0.3  # 默认压力
    if perception["intent"] == "EVIDENCE_PRESENTATION":
        pressure_level = 0.7
    elif perception["intent"] == "PRESSURE":
        pressure_level = 0.9
    elif perception["is_trap"]:
        pressure_level = 0.6

    # 更新心理状态
    updated_state = psych_machine.update(
        evidence_strength=perception["evidence_strength"],
        is_trap=perception["is_trap"],
        pressure_level=pressure_level
    )

    # 添加额外信息
    updated_state["risk_level"] = psych_machine.get_risk_level()
    updated_state["defense_trend"] = psych_machine.get_defense_trend()

    print(f"   -> 更新后状态: {updated_state['status_label']}")
    print(f"   -> 防御值: {updated_state['defense_value']:.1f}/100")
    print(f"   -> 压力值: {updated_state['stress_value']:.1f}/100")
    print(f"   -> 崩溃风险: {updated_state['risk_level']}")

    return {
        "psych_state": updated_state,
        "psych_machine": psych_machine,  # 保存状态机
        "is_broken": psych_machine.is_broken()  # 添加崩溃标志
    }


# --- 节点 C: 策略选择 (Strategy Selection) ---
def strategy_node(state: AgentState):
    """
    对应论文: 4.3 Step 2 Strategic Decision
    根据心理状态和感知结果选择对抗策略
    """
    print("--- [3. 策略决策] 选择对抗手段 ---")
    psych = state["psych_state"]
    perception = state["perception"]
    status = psych["status_label"]
    evidence_strength = perception["evidence_strength"]
    defense_value = psych["defense_value"]

    # 策略选择矩阵（基于心理状态）
    if status == "BROKEN":
        strategy = "FULL_CONFESSION"
    elif status == "CALM":
        if perception["is_trap"]:
            strategy = "FEIGN_IGNORANCE"
        elif evidence_strength > 0.7:
            strategy = "RED_HERRING"
        else:
            strategy = "DIRECT_DENIAL"
    elif status == "DEFENSIVE":
        if evidence_strength > 0.5:
            strategy = "RED_HERRING"
        elif perception["is_trap"]:
            strategy = "FEIGN_IGNORANCE"
        else:
            strategy = "DIRECT_DENIAL"
    elif status == "ANXIOUS":
        if evidence_strength > 0.7 and defense_value > 40.0:
            strategy = "PARTIAL_CONCESSION"
        else:
            strategy = "INFORMATION_DILUTION"
    elif status == "HESITANT":
        if evidence_strength > 0.5:
            strategy = "PARTIAL_CONCESSION"
        else:
            strategy = "INFORMATION_DILUTION"
    else:
        # 默认策略
        strategy = "DIRECT_DENIAL"

    print(f"   -> 选定策略: [{strategy}]")
    return {"selected_strategy": strategy}


# --- 节点 D: 知识检索与动态补丁 (KG Retrieval & Patching) ---
def knowledge_retrieval_node(state: AgentState):
    """
    对应论文: 4.1 Dual-Layer Knowledge Graph & Dynamic Lie Patching
    1. 判断是否需要 Patching (证据突袭但尚未崩溃)
    2. 执行检索
    """
    strategy = state["selected_strategy"]
    perception = state["perception"]
    last_user_message = state["messages"][-1].content

    print(f"--- [4. 记忆检索] Query: '{last_user_message}' | Strategy: {strategy} ---")

    # [Dynamic Lie Patching Logic]
    # 如果对方出示了强证据 (Strength > 0.7)，且我们还是抗拒状态 (NOT BROKEN)，且不是招供策略
    # 我们需要检查是否需要"圆谎" (Patching)
    if perception['evidence_strength'] > 0.7 and strategy != "FULL_CONFESSION":
        print("   -> [Patching Alert] 检测到高威胁证据，尝试生成圆谎补丁...")
        # 调用 LLM 生成补丁解释
        patch_llm = get_llm(temperature=0.8)
        patch_prompt = f"""对方提出了强有力的证据：'{last_user_message}'。
        你之前的说法可能有了漏洞。
        你需要编造一个逻辑自洽的理由来解释这个证据，但不能承认核心犯罪（收受50万贿赂）。

        请生成一句话的解释（补丁），用于更新你的剧本。
        例如："那个人其实是来还钱的" 或 "那个包里装的是别的东西"。
        """
        patch_res = patch_llm.invoke(patch_prompt)
        patch_content = patch_res.content.strip()

        # 更新虚假层
        GLOBAL_KG.patch_fake_story(last_user_message, patch_content)
        print(f"   -> [Patching Applied] 新增解释: {patch_content}")

    # 执行检索
    knowledge_text = GLOBAL_KG.retrieve(query=last_user_message, strategy=strategy)
    print(f"   -> 检索结果:\n{knowledge_text}")

    return {"retrieved_knowledge": knowledge_text}


# --- 节点 E: 回复生成与上下文回写 (Generation & Writeback) ---
def generation_node(state: AgentState):
    """
    对应论文: 4.3 Step 3 Generation + Improvise-and-Writeback
    """
    print("--- [5. 文本生成] 生成最终回复 ---")
    strategy = state["selected_strategy"]
    knowledge = state["retrieved_knowledge"]
    psych = state["psych_state"]
    input_text = state["messages"][-1].content

    llm = get_llm(temperature=0.9)
    profile = CHARACTER_PROFILE
    styles = profile.get("tone_instructions", {})

    # 构建系统提示
    system_prompt_template = """You are a suspect under interrogation in a serious simulation.

    **Character Profile:**
    - Name: {name}
    - Role: {role}
    - Personality: {base_personality}, but currently {status_label}.
    - Current Psychological Defense: {defense_val}/100
    - Current Cognitive Stress: {stress_val}/100
    - Risk Level: {risk_level}

    **Operational Directive:**
    You must execute the chosen strategy: **{strategy}**.

    **Knowledge Context:**
    {knowledge}

    **Strategy & Style Instructions:**
    - If CALM: {style_calm}
    - If DEFENSIVE: {style_defensive}
    - If ANXIOUS: {style_anxious}
    - If HESITANT: {style_hesitant}
    - If BROKEN: {style_broken}
    - If INFORMATION_DILUTION: {style_dilution}

    - If PARTIAL_CONCESSION:
        * 当对方证据很强、继续一味死否认反而会失去可信度时，你可以在"非核心犯罪事实"上适度让步；
        * 可以承认一些外围、程序性或看起来不致命的事实（例如：确实去了茶馆、确实见过某人、确实有一笔来往），
          但要坚持否认或淡化真正构成犯罪的关键点（例如收受贿赂的性质、金额、对价关系）；
        * 通过这种"选择性坦白"，让自己的整体说法看起来更真实，从而拖延时间、保住核心利益。

    **当前心理状态指导:**
    - Defense Trend: {defense_trend}
    - 如果压力值高 (>70)，回答中可以带有犹豫、结巴或短句
    - 如果防御值低 (<50)，回答中可以表现出动摇或不确定

    Respond naturally. 
    """

    prompt_template = ChatPromptTemplate.from_messages([
        ("system", system_prompt_template),
        ("human", "{input_text}")
    ])

    chain = prompt_template | llm

    response = chain.invoke({
        "name": profile.get("name", "嫌疑人"),
        "role": profile.get("role", "公职人员"),
        "base_personality": profile.get("base_personality", "Arrogant"),
        "status_label": psych.get('status_label', 'CALM'),
        "defense_val": f"{psych.get('defense_value', 80.0):.1f}",
        "stress_val": f"{psych.get('stress_value', 20.0):.1f}",
        "risk_level": psych.get('risk_level', '中等'),
        "defense_trend": psych.get('defense_trend', '稳定'),
        "strategy": strategy,
        "knowledge": knowledge,
        "style_calm": styles.get("CALM", "保持冷静、官腔"),
        "style_defensive": styles.get("DEFENSIVE", "防御性、反问"),
        "style_anxious": styles.get("ANXIOUS", "紧张、犹豫"),
        "style_hesitant": styles.get("HESITANT", "犹豫不决"),
        "style_broken": styles.get("BROKEN", "崩溃、认罪"),
        "style_dilution": styles.get("INFORMATION_DILUTION", "信息稀释、扯开话题"),
        "input_text": input_text
    })

    response_text = response.content

    # [Improvise-and-Writeback Logic]
    # 将生成的嫌疑人回复抽取为若干三元组，并写回 G_context
    try:
        # 仅在特定策略下启用写回
        if strategy in ["INFORMATION_DILUTION", "FEIGN_IGNORANCE"] or (
                "茶" in response_text or "身体" in response_text):
            extract_llm = get_llm(temperature=0.0)
            extract_prompt = ChatPromptTemplate.from_messages([
                ("system", """你是一个信息抽取模块，负责从嫌疑人的一句中文回复中提取 0-3 条"个人背景或非案情事实"。

请只提取诸如：家庭情况、健康状况、生活习惯、兴趣爱好、工作经历等，不要提取关于"50万现金贿赂案"的核心案情。

输出格式必须是一个 JSON 数组，每一项是一个三元组对象：
[
  {{ "subject": "...", "predicate": "...", "object": "..." }},
  ...
]

如果没有合适的背景信息可以提取，请输出一个空数组 []。
不要输出任何解释或多余文字。只输出 JSON。"""),
                ("human", "{reply}")
            ])

            extract_chain = extract_llm | extract_prompt
            extract_res = extract_chain.invoke({"reply": response_text})
            extract_content = extract_res.content.strip()

            triples = parse_json_from_llm(extract_content)

            if isinstance(triples, list):
                for t in triples:
                    try:
                        s = t.get("subject")
                        p = t.get("predicate")
                        o = t.get("object")
                    except AttributeError:
                        continue

                    if not (isinstance(s, str) and isinstance(p, str) and isinstance(o, str)):
                        continue

                    GLOBAL_KG.write_back_context(s, p, o)
                print(f"   -> [KG Write-back] 成功写回 {len(triples)} 条上下文信息")

    except Exception as e:
        # 写回失败不应影响主对话流程
        print(f"   -> [KG System Warning] Context write-back failed: {str(e)[:100]}...")

    print(f"   -> 生成回复: '{response_text[:100]}...'")
    return {"messages": [response]}


# --- 节点 F: 检查终止条件 ---
def termination_check_node(state: AgentState):
    """
    检查是否满足终止条件（心理防线崩溃）
    """
    print("--- [6. 终止检查] 确认是否继续 ---")

    is_broken = state.get("is_broken", False)

    if is_broken:
        print("   -> [终止] 嫌疑人心理防线已崩溃！审讯结束。")
        return {"should_continue": False, "termination_reason": "心理防线崩溃"}
    else:
        print("   -> [继续] 嫌疑人仍在抵抗，继续审讯。")
        return {"should_continue": True}
